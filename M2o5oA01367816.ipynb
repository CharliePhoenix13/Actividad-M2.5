{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Fl-VZiMDEp2",
        "outputId": "910a197f-b17b-42fd-f744-4afa3cc1f090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 48s 30ms/step - loss: 1.4598 - accuracy: 0.4804 - val_loss: 1.3089 - val_accuracy: 0.5378\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 1.1512 - accuracy: 0.5958 - val_loss: 1.1043 - val_accuracy: 0.6129\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.0226 - accuracy: 0.6407 - val_loss: 1.1319 - val_accuracy: 0.6015\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.9373 - accuracy: 0.6712 - val_loss: 1.0469 - val_accuracy: 0.6369\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.8565 - accuracy: 0.7002 - val_loss: 1.0507 - val_accuracy: 0.6395\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 0.7946 - accuracy: 0.7209 - val_loss: 1.0270 - val_accuracy: 0.6474\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 0.7327 - accuracy: 0.7420 - val_loss: 1.0385 - val_accuracy: 0.6494\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.6745 - accuracy: 0.7640 - val_loss: 1.0648 - val_accuracy: 0.6450\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.6230 - accuracy: 0.7814 - val_loss: 1.1619 - val_accuracy: 0.6378\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5729 - accuracy: 0.7987 - val_loss: 1.1400 - val_accuracy: 0.6417\n",
            "313/313 - 2s - loss: 1.1400 - accuracy: 0.6417 - 2s/epoch - 7ms/step\n",
            "\n",
            "Test accuracy: 0.641700029373169\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define the variations of the CNN model\n",
        "def create_model(num_conv_layers, num_filters, use_dropout=False):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(num_filters, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    for _ in range(num_conv_layers - 1):\n",
        "        model.add(layers.Conv2D(num_filters, (3, 3), activation='relu'))\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    if use_dropout:\n",
        "        model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train and evaluate the models with different variations\n",
        "num_conv_layers_list = [2, 3]  # Try models with 2 and 3 convolutional layers\n",
        "num_filters_list = [32, 64]    # Try models with 32 and 64 filters\n",
        "use_dropout_list = [False, True]  # Try models without and with dropout\n",
        "\n",
        "for num_conv_layers in num_conv_layers_list:\n",
        "    for num_filters in num_filters_list:\n",
        "        for use_dropout in use_dropout_list:\n",
        "            model = create_model(num_conv_layers, num_filters, use_dropout)\n",
        "            model.compile(optimizer='adam',\n",
        "                          loss='sparse_categorical_crossentropy',\n",
        "                          metrics=['accuracy'])\n",
        "            print(\"\\nTraining model with {} convolutional layers, {} filters, dropout={}\".format(num_conv_layers, num_filters, use_dropout))\n",
        "            history = model.fit(train_images, train_labels, epochs=10,\n",
        "                                validation_data=(test_images, test_labels))\n",
        "            test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "            print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XSginTWXRgPW",
        "outputId": "4118db2b-91fb-4cd7-fb82-2e229310bafc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model with 2 convolutional layers, 32 filters, dropout=False\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 57s 36ms/step - loss: 1.4596 - accuracy: 0.4748 - val_loss: 1.2075 - val_accuracy: 0.5818\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 54s 34ms/step - loss: 1.1153 - accuracy: 0.6091 - val_loss: 1.0592 - val_accuracy: 0.6276\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.9894 - accuracy: 0.6545 - val_loss: 0.9800 - val_accuracy: 0.6596\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.9004 - accuracy: 0.6850 - val_loss: 0.9645 - val_accuracy: 0.6668\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8334 - accuracy: 0.7084 - val_loss: 0.9599 - val_accuracy: 0.6682\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.7700 - accuracy: 0.7324 - val_loss: 0.9315 - val_accuracy: 0.6874\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 54s 34ms/step - loss: 0.7179 - accuracy: 0.7511 - val_loss: 0.9325 - val_accuracy: 0.6857\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - loss: 0.6604 - accuracy: 0.7676 - val_loss: 0.9021 - val_accuracy: 0.6964\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - loss: 0.6146 - accuracy: 0.7853 - val_loss: 0.9365 - val_accuracy: 0.6931\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5745 - accuracy: 0.7996 - val_loss: 0.9703 - val_accuracy: 0.6890\n",
            "313/313 - 3s - loss: 0.9703 - accuracy: 0.6890 - 3s/epoch - 8ms/step\n",
            "Test accuracy: 0.6890000104904175\n",
            "\n",
            "Training model with 2 convolutional layers, 32 filters, dropout=True\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 59s 37ms/step - loss: 1.5622 - accuracy: 0.4309 - val_loss: 1.3174 - val_accuracy: 0.5274\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 54s 35ms/step - loss: 1.2908 - accuracy: 0.5388 - val_loss: 1.1129 - val_accuracy: 0.6069\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 56s 36ms/step - loss: 1.1770 - accuracy: 0.5821 - val_loss: 1.0835 - val_accuracy: 0.6247\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 1.1038 - accuracy: 0.6106 - val_loss: 0.9696 - val_accuracy: 0.6614\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 56s 36ms/step - loss: 1.0468 - accuracy: 0.6297 - val_loss: 0.9447 - val_accuracy: 0.6667\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.9980 - accuracy: 0.6500 - val_loss: 0.9001 - val_accuracy: 0.6893\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.9643 - accuracy: 0.6611 - val_loss: 0.8945 - val_accuracy: 0.6855\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 56s 36ms/step - loss: 0.9297 - accuracy: 0.6744 - val_loss: 0.8528 - val_accuracy: 0.7031\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 54s 35ms/step - loss: 0.9005 - accuracy: 0.6825 - val_loss: 0.8531 - val_accuracy: 0.7020\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.8809 - accuracy: 0.6905 - val_loss: 0.8472 - val_accuracy: 0.7062\n",
            "313/313 - 3s - loss: 0.8472 - accuracy: 0.7062 - 3s/epoch - 11ms/step\n",
            "Test accuracy: 0.7062000036239624\n",
            "\n",
            "Training model with 2 convolutional layers, 64 filters, dropout=False\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 116s 74ms/step - loss: 1.4038 - accuracy: 0.4969 - val_loss: 1.1214 - val_accuracy: 0.6079\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 117s 75ms/step - loss: 1.0446 - accuracy: 0.6358 - val_loss: 0.9878 - val_accuracy: 0.6580\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 112s 71ms/step - loss: 0.8928 - accuracy: 0.6881 - val_loss: 0.9011 - val_accuracy: 0.6916\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 0.7950 - accuracy: 0.7218 - val_loss: 0.9020 - val_accuracy: 0.6933\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 111s 71ms/step - loss: 0.7052 - accuracy: 0.7531 - val_loss: 0.8549 - val_accuracy: 0.7107\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 118s 75ms/step - loss: 0.6294 - accuracy: 0.7806 - val_loss: 0.8532 - val_accuracy: 0.7142\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 111s 71ms/step - loss: 0.5671 - accuracy: 0.8005 - val_loss: 0.9257 - val_accuracy: 0.6954\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 108s 69ms/step - loss: 0.4996 - accuracy: 0.8252 - val_loss: 0.9249 - val_accuracy: 0.7110\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 115s 74ms/step - loss: 0.4454 - accuracy: 0.8428 - val_loss: 0.9618 - val_accuracy: 0.7056\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 111s 71ms/step - loss: 0.3850 - accuracy: 0.8625 - val_loss: 1.0385 - val_accuracy: 0.7118\n",
            "313/313 - 5s - loss: 1.0385 - accuracy: 0.7118 - 5s/epoch - 15ms/step\n",
            "Test accuracy: 0.7117999792098999\n",
            "\n",
            "Training model with 2 convolutional layers, 64 filters, dropout=True\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 117s 74ms/step - loss: 1.4985 - accuracy: 0.4588 - val_loss: 1.2122 - val_accuracy: 0.5665\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 112s 72ms/step - loss: 1.2027 - accuracy: 0.5742 - val_loss: 1.0552 - val_accuracy: 0.6295\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 112s 72ms/step - loss: 1.0782 - accuracy: 0.6218 - val_loss: 1.0031 - val_accuracy: 0.6500\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 112s 72ms/step - loss: 0.9977 - accuracy: 0.6498 - val_loss: 0.9299 - val_accuracy: 0.6739\n",
            "Epoch 5/10\n",
            "1213/1563 [======================>.......] - ETA: 23s - loss: 0.9289 - accuracy: 0.6752"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-4-6dfe6a848fe4>\", line 43, in <cell line: 35>\n",
            "    history = model.fit(train_images, train_labels, epochs=10,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n",
            "    tmp_logs = self.train_function(iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 832, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 868, in _call\n",
            "    return tracing_compilation.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
            "    return function._call_flat(  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1323, in _call_flat\n",
            "    return self._inference_function.call_preflattened(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
            "    flat_outputs = self.call_flat(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
            "    outputs = self._bound_context.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\", line 1486, in call_function\n",
            "    outputs = execute.execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
            "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 878, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 396, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, strict, {})\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 431, in _joinrealpath\n",
            "    st = os.lstat(newpath)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-6dfe6a848fe4>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTraining model with {} convolutional layers, {} filters, dropout={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_conv_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             history = model.fit(train_images, train_labels, epochs=10, \n\u001b[0m\u001b[1;32m     44\u001b[0m                                 validation_data=(test_images, test_labels))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Split the training set into training and validation sets\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Define a function to create the CNN model\n",
        "def create_model(learning_rate=0.001):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define hyperparameters to search\n",
        "learning_rates = [0.001, 0.0001]\n",
        "batch_sizes = [32, 64]\n",
        "num_epochs = [10, 20]\n",
        "\n",
        "best_accuracy = 0\n",
        "best_hyperparams = {}\n",
        "\n",
        "# Iterate over hyperparameters\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        for epochs in num_epochs:\n",
        "            print(\"\\nTraining model with LR={}, Batch Size={}, Epochs={}\".format(lr, batch_size, epochs))\n",
        "            model = create_model(learning_rate=lr)\n",
        "            history = model.fit(train_images, train_labels, epochs=epochs, batch_size=batch_size,\n",
        "                                validation_data=(val_images, val_labels), verbose=0)\n",
        "\n",
        "            # Evaluate the model on the validation set\n",
        "            val_loss, val_accuracy = model.evaluate(val_images, val_labels, verbose=0)\n",
        "            print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "            # Check if this combination of hyperparameters gives the best validation accuracy\n",
        "            if val_accuracy > best_accuracy:\n",
        "                best_accuracy = val_accuracy\n",
        "                best_hyperparams = {'learning_rate': lr, 'batch_size': batch_size, 'epochs': epochs}\n",
        "\n",
        "print(\"\\nBest hyperparameters:\", best_hyperparams)\n",
        "\n",
        "# Train the model with the best hyperparameters on the full training set\n",
        "best_model = create_model(learning_rate=best_hyperparams['learning_rate'])\n",
        "best_model.fit(train_images, train_labels, epochs=best_hyperparams['epochs'],\n",
        "               batch_size=best_hyperparams['batch_size'], verbose=1)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "test_loss, test_accuracy = best_model.evaluate(test_images, test_labels, verbose=2)\n",
        "print('Test accuracy:', test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3R9XVgfdONi",
        "outputId": "a1506427-d6d2-461f-e586-1d21c7353bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model with LR=0.001, Batch Size=32, Epochs=10\n",
            "Validation Accuracy: 0.6395999789237976\n",
            "\n",
            "Training model with LR=0.001, Batch Size=32, Epochs=20\n",
            "Validation Accuracy: 0.607200026512146\n",
            "\n",
            "Training model with LR=0.001, Batch Size=64, Epochs=10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define the baseline CNN model\n",
        "def create_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "# Define the CNN model with batch normalization\n",
        "def create_bn_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define the CNN model with data augmentation\n",
        "def create_augmented_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define the CNN model with transfer learning (VGG16)\n",
        "def create_transfer_learning_model():\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "    base_model.trainable = False  # Freeze the VGG16 base model\n",
        "\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train and evaluate baseline model\n",
        "baseline_model = create_model()\n",
        "baseline_history = baseline_model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Train and evaluate batch normalization model\n",
        "bn_model = create_bn_model()\n",
        "bn_history = bn_model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Train and evaluate data augmentation model\n",
        "train_generator = datagen.flow(train_images, train_labels, batch_size=32)\n",
        "augmented_model = create_augmented_model()\n",
        "augmented_history = augmented_model.fit(train_generator, steps_per_epoch=len(train_images) // 32, epochs=10, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Train and evaluate transfer learning model\n",
        "transfer_learning_model = create_transfer_learning_model()\n",
        "transfer_learning_history = transfer_learning_model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate models\n",
        "baseline_loss, baseline_accuracy = baseline_model.evaluate(test_images, test_labels, verbose=0)\n",
        "bn_loss, bn_accuracy = bn_model.evaluate(test_images, test_labels, verbose=0)\n",
        "augmented_loss, augmented_accuracy = augmented_model.evaluate(test_images, test_labels, verbose=0)\n",
        "transfer_learning_loss, transfer_learning_accuracy = transfer_learning_model.evaluate(test_images, test_labels, verbose=0)\n",
        "\n",
        "print(\"Baseline Model Accuracy:\", baseline_accuracy)\n",
        "print(\"Batch Normalization Model Accuracy:\", bn_accuracy)\n",
        "print(\"Data Augmentation Model Accuracy:\", augmented_accuracy)\n",
        "print(\"Transfer Learning Model Accuracy:\", transfer_learning_accuracy)"
      ],
      "metadata": {
        "id": "P6Ge3MQafYoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb6d4be-dfa2-41b0-b607-4d15da728588"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 80s 50ms/step - loss: 1.4825 - accuracy: 0.4611 - val_loss: 1.2091 - val_accuracy: 0.5696\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 77s 49ms/step - loss: 1.1097 - accuracy: 0.6100 - val_loss: 1.0123 - val_accuracy: 0.6465\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 80s 51ms/step - loss: 0.9512 - accuracy: 0.6670 - val_loss: 0.9710 - val_accuracy: 0.6580\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 82s 52ms/step - loss: 0.8426 - accuracy: 0.7075 - val_loss: 0.9214 - val_accuracy: 0.6784\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 79s 50ms/step - loss: 0.7622 - accuracy: 0.7329 - val_loss: 0.8710 - val_accuracy: 0.6962\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 78s 50ms/step - loss: 0.6928 - accuracy: 0.7571 - val_loss: 0.8636 - val_accuracy: 0.7028\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 76s 49ms/step - loss: 0.6323 - accuracy: 0.7771 - val_loss: 0.8571 - val_accuracy: 0.7135\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.5756 - accuracy: 0.7964 - val_loss: 0.8678 - val_accuracy: 0.7134\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 78s 50ms/step - loss: 0.5240 - accuracy: 0.8153 - val_loss: 0.9343 - val_accuracy: 0.7076\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 79s 51ms/step - loss: 0.4789 - accuracy: 0.8302 - val_loss: 0.9247 - val_accuracy: 0.7203\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 105s 66ms/step - loss: 1.3090 - accuracy: 0.5368 - val_loss: 1.6957 - val_accuracy: 0.4789\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 0.9372 - accuracy: 0.6707 - val_loss: 1.1631 - val_accuracy: 0.6035\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 103s 66ms/step - loss: 0.7782 - accuracy: 0.7268 - val_loss: 1.3754 - val_accuracy: 0.5661\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 0.6649 - accuracy: 0.7671 - val_loss: 0.8318 - val_accuracy: 0.7169\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 103s 66ms/step - loss: 0.5772 - accuracy: 0.7979 - val_loss: 1.0597 - val_accuracy: 0.6683\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 106s 68ms/step - loss: 0.5041 - accuracy: 0.8207 - val_loss: 0.9467 - val_accuracy: 0.6936\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 0.4372 - accuracy: 0.8462 - val_loss: 0.9027 - val_accuracy: 0.7217\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 103s 66ms/step - loss: 0.3810 - accuracy: 0.8645 - val_loss: 0.9334 - val_accuracy: 0.7232\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 0.3263 - accuracy: 0.8829 - val_loss: 0.9790 - val_accuracy: 0.7274\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 103s 66ms/step - loss: 0.2892 - accuracy: 0.8974 - val_loss: 0.9423 - val_accuracy: 0.7360\n",
            "Epoch 1/10\n",
            "1562/1562 [==============================] - 110s 70ms/step - loss: 1.6165 - accuracy: 0.1041 - val_loss: 1.2997 - val_accuracy: 0.1054\n",
            "Epoch 2/10\n",
            "1562/1562 [==============================] - 114s 73ms/step - loss: 1.3017 - accuracy: 0.0973 - val_loss: 1.1679 - val_accuracy: 0.0834\n",
            "Epoch 3/10\n",
            "1562/1562 [==============================] - 116s 74ms/step - loss: 1.1711 - accuracy: 0.0988 - val_loss: 1.0577 - val_accuracy: 0.0686\n",
            "Epoch 4/10\n",
            "1562/1562 [==============================] - 119s 76ms/step - loss: 1.0849 - accuracy: 0.0985 - val_loss: 0.9607 - val_accuracy: 0.0941\n",
            "Epoch 5/10\n",
            "1562/1562 [==============================] - 114s 73ms/step - loss: 1.0224 - accuracy: 0.1002 - val_loss: 0.9392 - val_accuracy: 0.1301\n",
            "Epoch 6/10\n",
            "1562/1562 [==============================] - 114s 73ms/step - loss: 0.9843 - accuracy: 0.1013 - val_loss: 0.8967 - val_accuracy: 0.1242\n",
            "Epoch 7/10\n",
            "1562/1562 [==============================] - 110s 70ms/step - loss: 0.9456 - accuracy: 0.1004 - val_loss: 0.8820 - val_accuracy: 0.0736\n",
            "Epoch 8/10\n",
            "1562/1562 [==============================] - 108s 69ms/step - loss: 0.9132 - accuracy: 0.1001 - val_loss: 0.8267 - val_accuracy: 0.1105\n",
            "Epoch 9/10\n",
            "1562/1562 [==============================] - 108s 69ms/step - loss: 0.8893 - accuracy: 0.1001 - val_loss: 0.8136 - val_accuracy: 0.1099\n",
            "Epoch 10/10\n",
            "1562/1562 [==============================] - 110s 70ms/step - loss: 0.8645 - accuracy: 0.1012 - val_loss: 0.8058 - val_accuracy: 0.0902\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 758s 485ms/step - loss: 1.3694 - accuracy: 0.5230 - val_loss: 1.2381 - val_accuracy: 0.5650\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 758s 485ms/step - loss: 1.1863 - accuracy: 0.5868 - val_loss: 1.2194 - val_accuracy: 0.5723\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 755s 483ms/step - loss: 1.1299 - accuracy: 0.6050 - val_loss: 1.1635 - val_accuracy: 0.5924\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 775s 496ms/step - loss: 1.0883 - accuracy: 0.6178 - val_loss: 1.1562 - val_accuracy: 0.5980\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 772s 494ms/step - loss: 1.0514 - accuracy: 0.6339 - val_loss: 1.1399 - val_accuracy: 0.5986\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 774s 495ms/step - loss: 1.0202 - accuracy: 0.6446 - val_loss: 1.1369 - val_accuracy: 0.6019\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 775s 496ms/step - loss: 0.9948 - accuracy: 0.6531 - val_loss: 1.1277 - val_accuracy: 0.6112\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 775s 496ms/step - loss: 0.9712 - accuracy: 0.6608 - val_loss: 1.1180 - val_accuracy: 0.6152\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 775s 496ms/step - loss: 0.9469 - accuracy: 0.6667 - val_loss: 1.1208 - val_accuracy: 0.6149\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 776s 496ms/step - loss: 0.9243 - accuracy: 0.6759 - val_loss: 1.1207 - val_accuracy: 0.6146\n",
            "Baseline Model Accuracy: 0.720300018787384\n",
            "Batch Normalization Model Accuracy: 0.7360000014305115\n",
            "Data Augmentation Model Accuracy: 0.09019999951124191\n",
            "Transfer Learning Model Accuracy: 0.6146000027656555\n"
          ]
        }
      ]
    }
  ]
}